{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkDfzauwCGVe"
   },
   "source": [
    "###Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KB8oZ33j570E",
    "outputId": "30b9df61-e335-4a8c-f577-ffe73996d8a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RMVcs2AoHoVZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets ,models,transforms\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Conv2d, MaxPool2d, Module\n",
    "from torch.optim import Adam\n",
    "import pandas as pd\n",
    "import os, shutil\n",
    "from os import listdir\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nci4NfRFbTGM",
    "outputId": "587aba9f-c3e3-414f-c685-09765a99c78c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1l8YzfPxHeMuLfUdSILbbb7gK98d3a9Ja\n",
      "To: /content/split_.zip\n",
      "100% 4.56G/4.56G [00:38<00:00, 119MB/s] \n"
     ]
    }
   ],
   "source": [
    "!gdown --id '1l8YzfPxHeMuLfUdSILbbb7gK98d3a9Ja'\n",
    "!unzip -q split_.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0E39_pW9P-tC",
    "outputId": "7fb44c58-ff95-4f95-dfce-7375b218219f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train neg  2484\n",
      "train pos  2484\n",
      "test neg  359\n",
      "test pos  45\n",
      "val neg  363\n",
      "val pos  44\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "path, dirs, files = next(os.walk(\"content/drive/MyDrive/split/train/negative\"))\n",
    "print(\"train neg \",len(files))\n",
    "path, dirs, files = next(os.walk(\"content/drive/MyDrive/split/train/positive\"))\n",
    "print(\"train pos \",len(files))\n",
    "path, dirs, files = next(os.walk(\"content/drive/MyDrive/split/test/negative\"))\n",
    "print(\"test neg \",len(files))\n",
    "path, dirs, files = next(os.walk(\"content/drive/MyDrive/split/test/positive\"))\n",
    "print(\"test pos \",len(files))\n",
    "path, dirs, files = next(os.walk(\"content/drive/MyDrive/split/val/negative\"))\n",
    "print(\"val neg \",len(files))\n",
    "path, dirs, files = next(os.walk(\"content/drive/MyDrive/split/val/positive\"))\n",
    "print(\"val pos \",len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJpfESMizbgb"
   },
   "source": [
    "### Transform to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VFcTGGhozXBU"
   },
   "outputs": [],
   "source": [
    "# raw img size 4040 * 5416 pixel\n",
    "wid = 1000\n",
    "hgt = 1000\n",
    "\n",
    "train_tfm = transforms.Compose([\n",
    "    transforms.Resize((1000, 1000)),\n",
    "    # transforms.ColorJitter(contrast=1),\n",
    "    # transforms.RandomRotation(degrees = 8, fill = 1),\n",
    "    # transforms.Resize((128, 128)),\n",
    "    # transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((1000, 1000)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# input[512, 1, 28, 28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJpzd9Z16Zqy"
   },
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ph4o1U5WnxGd"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "#train_set = datasets.DatasetFolder(\"split/train\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\n",
    "subtrain_set = datasets.DatasetFolder(\"split/train\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=train_tfm)\n",
    "valid_set = datasets.DatasetFolder(\"split/val\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n",
    "test_set = datasets.DatasetFolder(\"split/test\", loader=lambda x: Image.open(x), extensions=\"jpg\", transform=test_tfm)\n",
    "\n",
    "#train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True) # , num_workers=8, pin_memory=True\n",
    "subtrain_loader = DataLoader(subtrain_set, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v70BfWBdxahw"
   },
   "source": [
    "### MLP (博任)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zhq7ahtUitEG"
   },
   "outputs": [],
   "source": [
    "# dataiter = iter(train_loader)\n",
    "# images, labels = dataiter.next()\n",
    "\n",
    "# print(images.shape)\n",
    "# print(labels.shape)\n",
    "#CUDA_LAUNCH_BLOCKING=1\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "V9sw6FqSzEG8"
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules.activation import Sigmoid\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # The arguments for commonly used modules:\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "\n",
    "        # input image size: [1, 784, 784]  (C H W)\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, 1, 1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, 1, 1),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, 1, 1),\n",
    "            # nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2, 0),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(1000000, 128),  # * 196 * 196\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input (x): [batch_size, 3, 28, 28]\n",
    "        # output: [batch_size, 2]\n",
    "\n",
    "        # Extract features by convolutional layers.\n",
    "        x = self.cnn_layers(x)\n",
    "\n",
    "        # The extracted feature map must be flatten before going to fully-connected layers.\n",
    "        x = x.flatten(1)\n",
    "\n",
    "        # The features are transformed by fully-connected layers to obtain the final logits.\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGQdmVOu6Rqb",
    "outputId": "4f3821d3-0a05-4bca-c7e0-3e9763502a57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "print(\"Running on device: \", device)\n",
    "my_model = Classifier().to(device)\n",
    "my_model.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CkMQ3yhxX_8l"
   },
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(my_model.parameters(), lr=0.0001)\n",
    "# Binary Cross Entropy Loss\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "#loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "T_7QjaYfYDyU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Loss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oplab\\AppData\\Local\\Temp/ipykernel_4144/1098009433.py:69: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  validoutputs_array = np.array(validoutputs_list)\n",
      "C:\\Users\\oplab\\AppData\\Local\\Temp/ipykernel_4144/1098009433.py:69: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  validoutputs_array = np.array(validoutputs_list)\n",
      "C:\\Users\\oplab\\AppData\\Local\\Temp/ipykernel_4144/1098009433.py:74: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  validtargets_array = np.array(validtargets_list)\n",
      "C:\\Users\\oplab\\AppData\\Local\\Temp/ipykernel_4144/1098009433.py:74: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  validtargets_array = np.array(validtargets_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 10: trainingLoss = 0.869, validationLoss = 0.699 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 20: trainingLoss = 0.781, validationLoss = 0.671 (minibatch size = 16)\n",
      "Oh yah\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 30: trainingLoss = 0.753, validationLoss = 0.816 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 40: trainingLoss = 0.741, validationLoss = 0.608 (minibatch size = 16)\n",
      "Oh yah\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 50: trainingLoss = 0.723, validationLoss = 0.582 (minibatch size = 16)\n",
      "Oh yah\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 60: trainingLoss = 0.715, validationLoss = 0.771 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 70: trainingLoss = 0.712, validationLoss = 0.533 (minibatch size = 16)\n",
      "Oh yah\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 80: trainingLoss = 0.707, validationLoss = 0.594 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 90: trainingLoss = 0.703, validationLoss = 0.585 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 100: trainingLoss = 0.699, validationLoss = 0.806 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 110: trainingLoss = 0.696, validationLoss = 0.645 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 120: trainingLoss = 0.693, validationLoss = 0.679 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 130: trainingLoss = 0.688, validationLoss = 0.711 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 140: trainingLoss = 0.680, validationLoss = 0.477 (minibatch size = 16)\n",
      "Oh yah\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 150: trainingLoss = 0.680, validationLoss = 0.594 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 160: trainingLoss = 0.676, validationLoss = 0.694 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 170: trainingLoss = 0.674, validationLoss = 0.548 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 180: trainingLoss = 0.670, validationLoss = 0.690 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 190: trainingLoss = 0.669, validationLoss = 0.603 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 200: trainingLoss = 0.666, validationLoss = 0.598 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 210: trainingLoss = 0.663, validationLoss = 0.636 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 220: trainingLoss = 0.662, validationLoss = 0.623 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 230: trainingLoss = 0.660, validationLoss = 0.542 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 240: trainingLoss = 0.660, validationLoss = 0.795 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 250: trainingLoss = 0.657, validationLoss = 0.475 (minibatch size = 16)\n",
      "Oh yah\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 260: trainingLoss = 0.657, validationLoss = 0.670 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 270: trainingLoss = 0.654, validationLoss = 0.757 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 280: trainingLoss = 0.652, validationLoss = 0.413 (minibatch size = 16)\n",
      "Oh yah\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 290: trainingLoss = 0.652, validationLoss = 0.682 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 300: trainingLoss = 0.650, validationLoss = 0.606 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 0 Batch 310: trainingLoss = 0.648, validationLoss = 0.715 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 320: trainingLoss = 0.645, validationLoss = 0.577 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 330: trainingLoss = 0.643, validationLoss = 0.799 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 340: trainingLoss = 0.640, validationLoss = 0.536 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 350: trainingLoss = 0.637, validationLoss = 0.549 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 360: trainingLoss = 0.633, validationLoss = 0.592 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 370: trainingLoss = 0.628, validationLoss = 1.080 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 380: trainingLoss = 0.624, validationLoss = 0.455 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 390: trainingLoss = 0.621, validationLoss = 0.464 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 400: trainingLoss = 0.619, validationLoss = 0.787 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 410: trainingLoss = 0.616, validationLoss = 0.628 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 420: trainingLoss = 0.612, validationLoss = 0.688 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 430: trainingLoss = 0.607, validationLoss = 0.597 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 440: trainingLoss = 0.603, validationLoss = 0.674 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 450: trainingLoss = 0.599, validationLoss = 0.493 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 460: trainingLoss = 0.596, validationLoss = 0.588 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 470: trainingLoss = 0.591, validationLoss = 0.537 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 480: trainingLoss = 0.587, validationLoss = 0.367 (minibatch size = 16)\n",
      "Oh yah\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 490: trainingLoss = 0.586, validationLoss = 0.483 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 500: trainingLoss = 0.583, validationLoss = 0.677 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 510: trainingLoss = 0.579, validationLoss = 0.727 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 520: trainingLoss = 0.576, validationLoss = 0.734 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 530: trainingLoss = 0.573, validationLoss = 0.412 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 540: trainingLoss = 0.570, validationLoss = 0.628 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 550: trainingLoss = 0.567, validationLoss = 0.578 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 560: trainingLoss = 0.563, validationLoss = 0.487 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 570: trainingLoss = 0.560, validationLoss = 0.484 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 580: trainingLoss = 0.556, validationLoss = 1.077 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 590: trainingLoss = 0.553, validationLoss = 0.479 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 600: trainingLoss = 0.551, validationLoss = 0.459 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 610: trainingLoss = 0.548, validationLoss = 0.822 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 1 Batch 620: trainingLoss = 0.545, validationLoss = 0.712 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 630: trainingLoss = 0.541, validationLoss = 0.655 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 640: trainingLoss = 0.536, validationLoss = 0.774 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 650: trainingLoss = 0.531, validationLoss = 0.551 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 660: trainingLoss = 0.526, validationLoss = 0.449 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 670: trainingLoss = 0.521, validationLoss = 1.278 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 680: trainingLoss = 0.517, validationLoss = 0.953 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 690: trainingLoss = 0.512, validationLoss = 0.784 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 700: trainingLoss = 0.506, validationLoss = 0.820 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 710: trainingLoss = 0.502, validationLoss = 0.797 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 720: trainingLoss = 0.497, validationLoss = 0.865 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 730: trainingLoss = 0.493, validationLoss = 1.380 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 740: trainingLoss = 0.490, validationLoss = 0.939 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 750: trainingLoss = 0.486, validationLoss = 1.072 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 760: trainingLoss = 0.482, validationLoss = 0.582 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 770: trainingLoss = 0.478, validationLoss = 0.749 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 780: trainingLoss = 0.474, validationLoss = 0.719 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 790: trainingLoss = 0.470, validationLoss = 0.468 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 800: trainingLoss = 0.466, validationLoss = 0.564 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 810: trainingLoss = 0.462, validationLoss = 0.601 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 820: trainingLoss = 0.458, validationLoss = 0.881 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 830: trainingLoss = 0.454, validationLoss = 0.752 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 840: trainingLoss = 0.450, validationLoss = 1.004 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 850: trainingLoss = 0.447, validationLoss = 1.414 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 860: trainingLoss = 0.444, validationLoss = 0.744 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 870: trainingLoss = 0.441, validationLoss = 0.499 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 880: trainingLoss = 0.438, validationLoss = 0.794 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 890: trainingLoss = 0.435, validationLoss = 1.319 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 900: trainingLoss = 0.432, validationLoss = 0.581 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 910: trainingLoss = 0.429, validationLoss = 0.680 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 920: trainingLoss = 0.425, validationLoss = 0.724 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 2 Batch 930: trainingLoss = 0.422, validationLoss = 0.751 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 940: trainingLoss = 0.419, validationLoss = 1.639 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 950: trainingLoss = 0.415, validationLoss = 0.681 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 960: trainingLoss = 0.411, validationLoss = 1.649 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 970: trainingLoss = 0.408, validationLoss = 0.780 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 980: trainingLoss = 0.405, validationLoss = 0.686 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 990: trainingLoss = 0.401, validationLoss = 0.638 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1000: trainingLoss = 0.398, validationLoss = 0.538 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1010: trainingLoss = 0.395, validationLoss = 1.434 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1020: trainingLoss = 0.392, validationLoss = 0.654 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1030: trainingLoss = 0.388, validationLoss = 0.818 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1040: trainingLoss = 0.385, validationLoss = 0.780 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1050: trainingLoss = 0.382, validationLoss = 0.655 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1060: trainingLoss = 0.380, validationLoss = 1.833 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1070: trainingLoss = 0.377, validationLoss = 0.836 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1080: trainingLoss = 0.374, validationLoss = 0.753 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1090: trainingLoss = 0.371, validationLoss = 1.176 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1100: trainingLoss = 0.368, validationLoss = 0.764 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1110: trainingLoss = 0.365, validationLoss = 0.769 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1120: trainingLoss = 0.363, validationLoss = 1.531 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1130: trainingLoss = 0.360, validationLoss = 0.772 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1140: trainingLoss = 0.357, validationLoss = 0.867 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1150: trainingLoss = 0.355, validationLoss = 0.862 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1160: trainingLoss = 0.352, validationLoss = 0.842 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1170: trainingLoss = 0.350, validationLoss = 0.925 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1180: trainingLoss = 0.347, validationLoss = 0.968 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1190: trainingLoss = 0.344, validationLoss = 1.042 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1200: trainingLoss = 0.342, validationLoss = 1.151 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1210: trainingLoss = 0.339, validationLoss = 1.768 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1220: trainingLoss = 0.337, validationLoss = 0.908 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1230: trainingLoss = 0.335, validationLoss = 0.849 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 3 Batch 1240: trainingLoss = 0.332, validationLoss = 0.831 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1250: trainingLoss = 0.330, validationLoss = 0.858 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1260: trainingLoss = 0.328, validationLoss = 0.863 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1270: trainingLoss = 0.325, validationLoss = 0.824 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1280: trainingLoss = 0.323, validationLoss = 0.983 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1290: trainingLoss = 0.321, validationLoss = 0.906 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1300: trainingLoss = 0.319, validationLoss = 1.537 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1310: trainingLoss = 0.316, validationLoss = 0.838 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1320: trainingLoss = 0.314, validationLoss = 1.225 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1330: trainingLoss = 0.312, validationLoss = 0.937 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1340: trainingLoss = 0.310, validationLoss = 1.075 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1350: trainingLoss = 0.308, validationLoss = 0.950 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1360: trainingLoss = 0.306, validationLoss = 0.908 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1370: trainingLoss = 0.303, validationLoss = 1.698 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1380: trainingLoss = 0.301, validationLoss = 0.947 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1390: trainingLoss = 0.299, validationLoss = 1.488 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1400: trainingLoss = 0.297, validationLoss = 0.984 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1410: trainingLoss = 0.296, validationLoss = 0.865 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1420: trainingLoss = 0.294, validationLoss = 3.925 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1430: trainingLoss = 0.293, validationLoss = 0.697 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1440: trainingLoss = 0.291, validationLoss = 0.975 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1450: trainingLoss = 0.289, validationLoss = 2.233 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1460: trainingLoss = 0.288, validationLoss = 0.547 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1470: trainingLoss = 0.286, validationLoss = 1.580 (minibatch size = 16)\n",
      "Calculating Loss...\n",
      "Epoch 4 Batch 1480: trainingLoss = 0.284, validationLoss = 0.916 (minibatch size = 16)\n",
      "early stop1\n",
      "early stop2\n"
     ]
    }
   ],
   "source": [
    "nepoch = 100\n",
    "step_count = 0\n",
    "log_interval = 10\n",
    "#trainingAccuracy_list = []\n",
    "#validationAccuracy_list = []\n",
    "trainingloss_list = []\n",
    "validloss_list = []\n",
    "step_count_list = []\n",
    "#train_ncorrect = 0\n",
    "#train_test_nobs = 0\n",
    "cumulative_loss = 0\n",
    "countdown = 100\n",
    "\n",
    "\n",
    "for epoch_id in range(0, nepoch):    \n",
    "    if countdown == 0:\n",
    "        print(\"early stop2\")\n",
    "        break  \n",
    "    for batch_idx, (inputs, targets) in enumerate(subtrain_loader):\n",
    "        #reshape target to two-dimensional array\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        step_count += 1        \n",
    "        my_model.train()\n",
    "        #print(inputs)\n",
    "        #print(targets)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "      \n",
    "        optimizer.zero_grad()\n",
    "        #batch_size = inputs.shape[0]\n",
    "        #inputs = inputs.view(batch_size, -1)\n",
    "        outputs = my_model(inputs)   \n",
    "        targets = targets.float()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        cumulative_loss += loss\n",
    "\n",
    "        #train_pred = (outputs.cpu().detach().numpy() > 0.5).astype('float32')\n",
    "        #train_tmp_correct = (train_pred == targets.cpu().detach().numpy()).sum()\n",
    "        #train_ncorrect += train_tmp_correct\n",
    "        #train_test_nobs += len(train_pred) \n",
    "  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #if step_count % log_interval == 0: \n",
    "        if step_count % log_interval == 0:\n",
    "            step_count_list.append(step_count)\n",
    "            #trainingAccuracy = train_ncorrect / train_test_nobs\n",
    "            #valid_ncorrect = 0\n",
    "            #valid_test_nobs = 0\n",
    "            validoutputs_list = []\n",
    "            validtargets_list = []\n",
    "            with torch.no_grad():\n",
    "              for i, (validinputs, validtargets) in enumerate(valid_loader):\n",
    "                if i == 0:\n",
    "                  print(\"Calculating Loss...\")\n",
    "                my_model.eval()\n",
    "                validtargets = validtargets.reshape((-1, 1))\n",
    "                validinputs, validtargets = validinputs.to(device), validtargets.to(device)\n",
    "                #batch_size = validinputs.shape[0]\n",
    "                #validinputs = validinputs.view(batch_size, -1)\n",
    "                validoutputs = my_model(validinputs) \n",
    "                validtargets = validtargets.float()\n",
    "                validoutputs_list.append(validoutputs)\n",
    "                validtargets_list.append(validtargets)\n",
    "                #valid_pred = (validoutputs.cpu().detach().numpy() > 0.5).astype('float32')\n",
    "                #valid_tmp_correct = (valid_pred == validtargets.cpu().detach().numpy()).sum()\n",
    "                #valid_ncorrect += valid_tmp_correct\n",
    "                #valid_test_nobs += len(valid_pred) \n",
    "            #validationAccuracy = valid_ncorrect / valid_test_nobs\n",
    "            validoutputs_array = np.array(validoutputs_list)\n",
    "            for i in range(len(validoutputs_array)):\n",
    "              validoutputs_array[i] = validoutputs_array[i].to(\"cpu\")\n",
    "              validoutputs_array[i] = validoutputs_array[i].numpy()\n",
    "            full_valid_outputs = np.concatenate(validoutputs_array, axis=0 )\n",
    "            validtargets_array = np.array(validtargets_list)\n",
    "            for i in range(len(validtargets_array)):\n",
    "              validtargets_array[i] = validtargets_array[i].to(\"cpu\")\n",
    "              validtargets_array[i] = validtargets_array[i].numpy()\n",
    "            full_valid_targets = np.concatenate(validtargets_array, axis=0 )\n",
    "            validloss = loss_fn(torch.tensor(full_valid_outputs), torch.tensor(full_valid_targets))\n",
    "            trainingloss = cumulative_loss / step_count\n",
    "            #trainingAccuracy_list.append(trainingAccuracy)\n",
    "            #validationAccuracy_list.append(validationAccuracy)\n",
    "            trainingloss_list.append(trainingloss.item())\n",
    "            validloss_list.append(validloss.item())\n",
    "            print(\"Epoch %d Batch %d: trainingLoss = %.3f, validationLoss = %.3f (minibatch size = %d)\" % (epoch_id, step_count, trainingloss.item(), validloss.item(), len(targets)))\n",
    "            #print(\"Epoch %d Batch %d: trainingAccuracy = %.3f, validationAccuracy = %.3f (minibatch size = %d)\" % (epoch_id, step_count, trainingAccuracy, validationAccuracy, len(targets)))        \n",
    "            if step_count < 20:\n",
    "                before_lowestloss = validloss\n",
    "                PATH = './CNN_final.pth' #save model\n",
    "                torch.save(my_model.state_dict(), PATH)\n",
    "                \n",
    "            elif step_count >=20:\n",
    "                if validloss < before_lowestloss:\n",
    "                    print(\"Oh yah\") #爽啦，進步了！\n",
    "                    PATH = './CNN_final.pth' #save model\n",
    "                    torch.save(my_model.state_dict(), PATH)\n",
    "                    before_lowestloss = validloss\n",
    "                    countdown = 100 #經過1000個batch相當於經過100個10個batch\n",
    "                else:\n",
    "                    countdown -= 1\n",
    "            if countdown == 0:\n",
    "                print(\"early stop1\") #好了啦\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xZj_j70MMIJY",
    "outputId": "5744557a-698b-40fd-b029-23e396afedac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.load_state_dict(torch.load(PATH)) #use the saved model to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "N8TmsQyTLq3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing model testing...\n",
      "Test loss = 0.386\n",
      "Accuracy = 0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oplab\\AppData\\Local\\Temp/ipykernel_4144/4192451914.py:30: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  outputs_array = np.array(outputs_list)\n",
      "C:\\Users\\oplab\\AppData\\Local\\Temp/ipykernel_4144/4192451914.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  outputs_array = np.array(outputs_list)\n",
      "C:\\Users\\oplab\\AppData\\Local\\Temp/ipykernel_4144/4192451914.py:35: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  targets_array = np.array(targets_list)\n",
      "C:\\Users\\oplab\\AppData\\Local\\Temp/ipykernel_4144/4192451914.py:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  targets_array = np.array(targets_list)\n"
     ]
    }
   ],
   "source": [
    "my_model.eval()\n",
    "print(\"Doing model testing...\")\n",
    "test_nobs = 0\n",
    "ncorrect = 0\n",
    "pred_list = []\n",
    "true_list = []\n",
    "outputs_list = []\n",
    "targets_list = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):            \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        #batch_size = inputs.shape[0]\n",
    "        #inputs = inputs.view(batch_size, -1)\n",
    "        outputs = my_model(inputs)\n",
    "        targets = targets.float()\n",
    "        outputs_list.append(outputs)\n",
    "        targets_list.append(targets)              \n",
    "        pred = (outputs.cpu().numpy() > 0.5).astype('float32')\n",
    "        pred_list.extend(pred.flatten().tolist())\n",
    "        true_list.extend(targets.flatten().tolist())\n",
    "        tmp_correct = (pred == targets.cpu().numpy()).sum()\n",
    "        ncorrect += tmp_correct\n",
    "        test_nobs += len(pred)        \n",
    "accuracy = ncorrect / test_nobs\n",
    "#print(np.array(outputs_list))\n",
    "#print(np.array(outputs_list).shape)\n",
    "#print(np.array(targets_list))\n",
    "#print(np.array(targets_list).shape)\n",
    "outputs_array = np.array(outputs_list)\n",
    "for i in range(len(outputs_array)):\n",
    "  outputs_array[i] = outputs_array[i].to(\"cpu\")\n",
    "  outputs_array[i] = outputs_array[i].numpy()\n",
    "full_test_outputs = np.concatenate(outputs_array, axis=0 )\n",
    "targets_array = np.array(targets_list)\n",
    "for i in range(len(targets_array)):\n",
    "  targets_array[i] = targets_array[i].to(\"cpu\")\n",
    "  targets_array[i] = targets_array[i].numpy()\n",
    "full_test_targets = np.concatenate(targets_array, axis=0 )\n",
    "testloss = loss_fn(torch.tensor(full_test_outputs), torch.tensor(full_test_targets))\n",
    "print(\"Test loss = %.3f\" % testloss.item())\n",
    "print(\"Accuracy = %.3f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gfsVHWPeL284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.96      0.93       359\n",
      "         1.0       0.35      0.16      0.22        45\n",
      "\n",
      "    accuracy                           0.87       404\n",
      "   macro avg       0.63      0.56      0.57       404\n",
      "weighted avg       0.84      0.87      0.85       404\n",
      "\n",
      "AUC: 0.5596719281956051\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(metrics.classification_report(true_list, pred_list))\n",
    "print(\"AUC:\",roc_auc_score(true_list, pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2NGsfRMNGzPq"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(step_count_list, trainingloss_list, label = \"training loss\")\n",
    "plt.plot(step_count_list, validloss_list, label = \"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rz43DMSneFBl"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(true_list, pred_list)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "Pytorch_Image_Classification_CNNwithDropout_FinalRun.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
